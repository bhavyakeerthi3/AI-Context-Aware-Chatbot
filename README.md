# AI-Context-Aware-Chatbot ğŸ¤–

<div align="center">
  <img src="https://img.shields.io/badge/Python-3.9+-3776AB?style=for-the-badge&logo=python&logoColor=white" />
  <img src="https://img.shields.io/badge/React-20232A?style=for-the-badge&logo=react&logoColor=61DAFB" />
  <img src="https://img.shields.io/badge/FastAPI-005571?style=for-the-badge&logo=fastapi" />
  <img src="https://img.shields.io/badge/Vite-646CFF?style=for-the-badge&logo=vite&logoColor=white" />
  <img src="https://img.shields.io/badge/Tailwind_CSS-38B2AC?style=for-the-badge&logo=tailwind-css&logoColor=white" />
</div>

---

## ğŸ“Œ Overview

**Aura AI** is a production-grade, context-aware conversational intelligence platform designed to deliver high-quality customer support and product engagement experiences. It leverages a high-performance **FastAPI** backend and a modern **React** frontend to demonstrate the practical application of advanced Natural Language Understanding (NLU) and real-time session memory.

Unlike conventional chatbots that respond in isolation, Aura AI maintains conversational context across turns, enabling intelligent follow-up responses and coherent multi-step interactions.

---

## ğŸ¯ Key Capabilities

### ğŸ§  Advanced Natural Language Understanding
- **Context Preservation** â€“ Maintains session-level memory for multi-turn conversations.
- **Intent Classification** â€“ Accurately identifies user goals such as Support Requests, Product Inquiries, and Order Status Checks.
- **Named Entity Recognition (NER)** â€“ Extracts product names, variants, and key attributes to ground conversations in real data.

### ğŸ¢ System Architecture & Design
- **Core NLU Engine** â€“ Lightweight, dependency-optimized Python engine engineered for speed and stability.
- **Knowledge-Grounded Responses** â€“ Answers retrieved from a structured knowledge base to ensure factual correctness.
- **Modern User Interface** â€“ Glassmorphic React interface with smooth animations and real-time typing indicators.

### âš™ Performance & Reliability
- **Asynchronous FastAPI** endpoints for low-latency responses.
- **Stateless API** with session-based memory management.
- **Modular architecture** enabling easy extension and scaling.

---

## ğŸ— Project Structure

```bash
Conversational-AI-Chatbot/
â”œâ”€â”€ backend/                # FastAPI Application
â”‚   â”œâ”€â”€ main.py             # API Endpoints & Orchestration
â”‚   â”œâ”€â”€ nlp_engine.py       # Intent & Entity logic
â”‚   â””â”€â”€ memory_manager.py   # Session & Context State
â”œâ”€â”€ frontend-react/         # React + Vite Application
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.jsx         # Chat Logic & Rendering
â”‚   â”‚   â””â”€â”€ App.css         # Professional Styling
â”‚   â””â”€â”€ vite.config.js      # Build & Dev tools
â””â”€â”€ data/
    â””â”€â”€ knowledge_base.json # Grounding Knowledge
```

---

## ï¿½ Getting Started

### Prerequisites
- Python 3.9+ ğŸ
- Node.js & npm ğŸ“¦

### 1ï¸âƒ£ Backend Setup
```bash
# Navigate to root
cd Conversational-AI-Chatbot

# Install requirements
pip install fastapi uvicorn pydantic requests

# Start the server
python -m uvicorn backend.main:app --host 0.0.0.0 --port 8002
```

### 2ï¸âƒ£ Frontend Setup
```bash
# Navigate to frontend folder
cd frontend-react

# Install dependencies
npm install

# Start the React dev server
npm run dev -- --port 3001
```

---

## ğŸ§ª Interactive Demo

Once both servers are running, navigate to `http://localhost:3001`.

### Try this flow:
1. **User**: "Tell me about the MacBook Pro."
2. **User**: "How much does it cost?"
3. **Aura**: *Recognizes "it" as the MacBook Pro and retrieves the price from the Knowledge Base.*

---

## ğŸ›  Tech Highlights

| Component | Technology | Role |
| :--- | :--- | :--- |
| **Backend** | FastAPI | High-performance API Gateway |
| **AI Logic** | Python NLU | Intent & Entity Orchestration |
| **Frontend** | React + Vite | Fast, Stateful User Interface |
| **Styling** | Modern CSS | Premium Glassmorphic Aesthetic |
| **Icons** | Lucide-React | Crisp, Scalable Visuals |

---

## ğŸ¤ Contributing

Contributions are what make the open-source community such an amazing place to learn, inspire, and create. Any contributions you make are **greatly appreciated**.

1. Fork the Project
2. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)
3. Commit your Changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the Branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## ğŸ™ Acknowledgements

- [Hugging Face](https://huggingface.co/) for the state-of-the-art NLP models.
- [Lucide](https://lucide.dev/) for the beautiful open-source icons.
- [FastAPI](https://fastapi.tiangolo.com/) for the incredibly fast web framework.
- [Vite](https://vitejs.dev/) for the lightning-fast frontend tooling.

---

## ğŸ“ License
This project is open-source and available under the MIT License.

---
<div align="center">
  <sub>Built with â¤ï¸ for professional AI engineering showcases.</sub>
</div>
